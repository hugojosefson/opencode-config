<?xml version="1.0" encoding="UTF-8"?>
<!--
COMPREHENSIVE CHART UPDATE PROMPT FOR model-speed-vs-coding-capability.svg:

HIDDEN PROMPT LOCATION: Find this hidden prompt in lines 2-38 of the XML comment section in model-speed-vs-coding-capability.svg

CURRENT REPOSITORY STATUS (as of 2025-10-02):
â€¢ 11 confirmed working GitHub Copilot models (61% success rate from 18 tested models)
â€¢ Multi-agent strategy: delegator (github-copilot/claude-3.5-sonnet), general (github-copilot/claude-sonnet-4.5), fallback (github-copilot/gpt-4o)
â€¢ Primary model: github-copilot/claude-sonnet-4.5 (most capable for complex coding tasks)
â€¢ Quality check command: deno task all
â€¢ Data sources: model-test-state.json, github-copilot-model-test-results.md, AGENTS.md

ðŸš¨ CRITICAL: DATA SOURCE UPDATE REQUIREMENTS ðŸš¨

âš ï¸  BEFORE UPDATING THIS CHART: You must first update the data sources using actual testing.
âš ï¸  DO NOT use potentially stale data from existing files without verification.
âš ï¸  Charts must reflect current model capabilities, not outdated test results.

DATA SOURCE UPDATE METHODS:

1. github-copilot-model-test-results.md UPDATE:
   Run systematic testing using real tool execution verification:
   ```bash
   # Basic functionality test  
   opencode run -model [MODEL] "respond with only '[MODEL] working'"
   
   # ACTUAL tool capability testing (replaces fake claim-based testing)
   opencode run -model [MODEL] "use the bash tool to run 'echo [MODEL] can use tools' and show the output"
   opencode run -model [MODEL] "use the read tool to show the contents of README.md"
   opencode run -model [MODEL] "use the glob tool to find all .md files in the current directory"
   
   # Delegation testing
   opencode run -agent delegator -model [MODEL] "tell your subagent to use bash tool with command 'echo [MODEL] can use bash' and respond back its response"
   
   # Example for specific model:
   opencode run -model github-copilot/claude-sonnet-4.5 "respond with only 'github-copilot/claude-sonnet-4.5 working'"
   opencode run -model github-copilot/claude-sonnet-4.5 "use the bash tool to run 'echo github-copilot/claude-sonnet-4.5 can use tools' and show the output"
   ```

2. model-test-state.json UPDATE:
   â€¢ This file updates automatically during testing (machine-readable state file)
   â€¢ Contains authoritative test results with timestamps and response times
   â€¢ Check openCodeTestDate field to verify freshness of test data
   â€¢ Only models with openCodeCompatible: true should be included in charts

3. DATA FRESHNESS VERIFICATION:
   â€¢ Check test dates in model-test-state.json (openCodeTestDate field)
   â€¢ Verify response times are from actual recent testing, not estimates
   â€¢ Confirm tool capabilities match current testing results
   â€¢ Cross-reference both files for consistency

TESTING WORKFLOW:

âš ï¸  CRITICAL: The old methodology of asking models to claim tool access was invalid and unreliable.
âš ï¸  Real tool execution must be tested to verify actual capability, not self-reported claims.

1. **ACTUAL TOOL CAPABILITY TESTING** (replaces fake claim-based testing):
   â€¢ **Basic tool test**: `opencode run -model [MODEL] "use the bash tool to run 'echo [MODEL] can use tools' and show the output"`
   â€¢ **File operation test**: `opencode run -model [MODEL] "use the read tool to show the contents of README.md"`  
   â€¢ **Search test**: `opencode run -model [MODEL] "use the glob tool to find all .md files in the current directory"`

2. **SUBAGENT DELEGATION TESTING** (new capability):
   â€¢ **Delegation test**: `opencode run -agent delegator -model [MODEL] "tell your subagent to use bash tool with command 'echo [MODEL] can use bash' and respond back its response"`
   â€¢ **Complex delegation test**: `opencode run -agent delegator -model [MODEL] "delegate to subagent: use read tool on config.json and summarize what you found"`

3. **RESULT INTERPRETATION** (updated for real testing):
   â€¢ **Tool Success**: Model successfully executes tool calls and shows real output
   â€¢ **Tool Failure**: Model cannot use tools, gives errors, or refuses to use tools
   â€¢ **Delegation Success**: Model can successfully delegate to subagents who execute tools
   â€¢ **Delegation Failure**: Model cannot delegate or subagents fail to execute

4. **CAPABILITY CLASSIFICATION** (new detailed breakdown):
   â€¢ **Excellent Tools**: Direct tool usage + subagent delegation both work
   â€¢ **Good Tools**: Direct tool usage works, delegation may have issues  
   â€¢ **Basic Tools**: Limited tool usage, no delegation capability
   â€¢ **No Tools**: Cannot use tools at all

5. **Result Documentation**:
   â€¢ Working models: Add to github-copilot-model-test-results.md with âœ…
   â€¢ Non-working models: Mark with âŒ and document specific failure
   â€¢ Record actual response times from testing output
   â€¢ Update model-test-state.json automatically captures test metadata

DATA VALIDATION REQUIREMENTS:

âœ… REQUIRED BEFORE CHART UPDATE:
â€¢ Run systematic model testing to update both data sources
â€¢ Verify openCodeTestDate is current (today's date) in model-test-state.json
â€¢ Confirm response times are from actual testing, not approximations
â€¢ Validate tool capabilities through ACTUAL tool execution testing (not claim-based testing)
â€¢ Test subagent delegation capabilities for multi-agent workflow validation
â€¢ Cross-reference model-test-state.json and github-copilot-model-test-results.md for consistency
â€¢ Only include models marked openCodeCompatible: true

UPDATE SEQUENCE (MANDATORY):
1. FIRST: Run systematic model testing using commands above
2. SECOND: Extract fresh data from newly updated sources  
3. THIRD: Update chart data points with verified current information
4. FOURTH: Update chart statistics, success rates, and key insights

âš ï¸  NEVER skip data source updates. Chart accuracy depends on current testing data, not stale files.

WORKING GITHUB COPILOT MODELS (12 total, speed-ordered fastest to slowest):
1. github-copilot/gpt-5-mini (1100ms, Elite tier) Â· lightweight
2. github-copilot/gemini-2.0-flash-001 (1200ms, Elite tier) Â· fast Google
3. github-copilot/gpt-4.1 (1300ms, Elite tier) Â· OpenAI flagship
4. github-copilot/claude-sonnet-4 (1350ms, Best tier) Â· PRIMARY MODEL
4. github-copilot/claude-sonnet-4.5 (1350ms, Best tier) Â· PRIMARY MODEL
5. github-copilot/claude-3.7-sonnet (1400ms, Best tier) Â· advanced reasoning
6. github-copilot/gpt-4o (1400ms, Elite tier) Â· FALLBACK MODEL
7. github-copilot/claude-3.7-sonnet-thought (1450ms, Best tier) Â· reasoning
8. github-copilot/claude-3.5-sonnet (1500ms, Best tier) Â· DELEGATOR MODEL
9. github-copilot/gpt-5 (1500ms, Elite tier) Â· OpenAI flagship
10. github-copilot/gemini-2.5-pro (1600ms, Best tier) Â· Google flagship
11. github-copilot/o3-mini (1800ms, Elite tier) Â· reasoning model

UPDATE PROCESS:
1. DATA SOURCES:
   â€¢ Primary: model-test-state.json (authoritative test results)
   â€¢ Secondary: github-copilot-model-test-results.md, AGENTS.md
   â€¢ Speed data: Response times from actual OpenCode testing (ms)
   â€¢ Capability: Evaluated through coding task performance and tool use quality
   â€¢ OpenCode compatibility: Only include models with openCodeCompatible: true

2. CHART POSITIONING (BROKEN Y-AXIS DESIGN):
   â€¢ X-axis = speed (faster models move right): 3000ms (left) to 250ms+ (right), logarithmic
   â€¢ Y-axis = coding quality (BROKEN AXIS - starts from Excellent level): 4-tier compressed system
   â€¢ Y-axis arrow: Points UPWARD indicating improvement toward better code quality
   â€¢ Speed calculation: (1000 - (speed_ms / 3000) * 900) bounded to chart area
   â€¢ Capability tiers (BROKEN AXIS): Best=150, Elite=250, Excellent=350, Professional=450
   â€¢ Chart height compressed from 600px to 400px with break indicator at bottom
   â€¢ Break indicator: zigzag lines at bottom showing axis discontinuity

3. COLLISION-FREE LABEL PLACEMENT SYSTEM (UPDATED):
   This chart uses collision-free external label placement to completely eliminate conflicts:
   
   â€¢ OpenAI Models (5 models): FAR RIGHT EXTERNAL labels (x: 1220-1400)
     - All OpenAI model labels positioned outside chart area on far right
     - Y-coordinates: 120-320 with 50px spacing for zero collisions
     - Curved callout lines navigate around ALL chart elements to external labels
   
   â€¢ Anthropic Models (4 models): FAR LEFT EXTERNAL labels (x: 20-200)
     - All Anthropic model labels positioned outside chart area on far left  
     - Y-coordinates: 120-270 with 50px spacing for zero collisions
     - Curved callout lines navigate around ALL chart elements to external labels
   
   â€¢ Google Models (2 models): TOP EXTERNAL labels (x: 400-600)
     - Google model labels positioned above chart area in top margin
     - Y-coordinates: 50-60 with clear separation from title/subtitle
     - Curved callout lines navigate around ALL chart elements to external labels
   
   AXIS ORIENTATION REQUIREMENTS:
   â€¢ Y-axis MUST point upward toward better code quality (visual arrow pointing up)
   â€¢ Higher Y-positions (lower pixel values) = better quality: Best=150, Elite=250, etc.
   â€¢ Ensure arrow direction clearly indicates "up = better" for code quality axis
   
   This collision-free system:
   - Positions ALL labels completely outside chart area boundaries
   - Uses expanded canvas (1600px width) to accommodate external label zones
   - Routes callout lines around grid, axes, legend, and all text elements
   - Maintains 50px minimum clearance from all chart components

4. VISUAL ENCODING:
   â€¢ Circle size: Large (8px) = flagship, Medium (7px) = standard, Small (6px) = lightweight
   â€¢ Provider colors: Anthropic=orange, Google=red, OpenAI=green (use existing CSS classes)
   â€¢ Code Quality Tiers (descriptive capability-based system):
     * Best: Advanced reasoning, comprehensive tool support, complex task handling
     * Elite: High capability, proven reliability, excellent performance
     * Excellent: Good capability, reliable tool usage, solid performance
     * Professional: Basic capability, functional but limited performance
   â€¢ Tool capability indicators based on ACTUAL tool execution testing:
     * Excellent Tools (solid border): Direct tool usage + subagent delegation both work
     * Good Tools (dashed border): Direct tool usage works, delegation may have issues
     * Basic Tools (dotted border): Limited tool usage, no delegation capability
     * No Tools: Not included on chart (models that cannot use tools)
   â€¢ All 11 confirmed working models have verified tool execution capability
   â€¢ NOTE: No numerical code quality scores exist - use tier names that represent capability levels

5. UPDATE REQUIREMENTS:
   â€¢ Model data points (circles + labels) with accurate positioning on broken axis
   â€¢ Follow collision-free external label placement system for zero conflicts
   â€¢ Title subtitle reflecting "11 Working Models" and 61% success rate
   â€¢ Key insights highlighting multi-agent strategy and primary/fallback models
   â€¢ Validation: Only include models marked openCodeCompatible: true in model-test-state.json
   â€¢ Repository context: OpenCode delegator/general/fallback agent architecture
   â€¢ Chart update prompt positioned in freed space at bottom of chart area

6. CHART STATUS AND INSIGHTS UPDATE REQUIREMENTS:
   
   TITLE SUBTITLE UPDATE:
   â€¢ Update "OpenCode-Compatible Models with Full Tool Support (X Working Models)" 
   â€¢ Replace X with current count of working models from fresh test results
   
   CHART UPDATE BOX UPDATE:
   â€¢ Update "X working / Y tested" with current numbers from test results
   â€¢ Update "Z% success rate" with calculated percentage (working/tested * 100)
   
   KEY INSIGHTS SECTION UPDATE (lines 396-409):
   â€¢ Update multi-agent strategy model assignments based on current repository config
   â€¢ Update primary model reference to match current config.json setting
   â€¢ Update working model count ("All X models confirmed working...")
   â€¢ Update quality check command if changed from "deno task all"
   â€¢ Update success rate percentage in final line
   â€¢ Ensure all referenced models are from the current working set
   
   PERFORMANCE INSIGHTS UPDATE:
   â€¢ Update fastest models list based on current response time data
   â€¢ Update speed leaders based on fresh test results
   â€¢ Update capability tier assignments based on actual tool testing results
    â€¢ Update provider distribution statistics (X Anthropic, Y OpenAI, Z Google models)

7. CALLOUT LINE VALIDATION (MANDATORY):
   
   CRITICAL ACCURACY REQUIREMENT:
   â€¢ Every model circle MUST connect to its correct label via callout lines
   â€¢ Every callout path endpoint MUST point directly to the model's correct label text
   â€¢ NO model may point to another model's label (critical labeling error)
   â€¢ NO two models may share the same callout endpoint coordinates
   
   VALIDATION PROCESS:
   1. Map each model circle position (cx, cy coordinates)
   2. Map each label text position (x, y coordinates) 
   3. Trace each callout path from model to endpoint
   4. Verify path endpoint matches the correct label position (within 5px tolerance)
   5. Ensure no duplicate endpoints or crossed connections
   6. Validate collision-free placement: All labels external to chart boundaries
   
   COMMON ERRORS TO PREVENT:
   â€¢ o3-mini pointing to gpt-5 label (wrong model name)
   â€¢ Multiple models sharing identical path endpoints
   â€¢ Labels positioned correctly but paths pointing to wrong labels
   â€¢ Path endpoints landing between two labels instead of precisely on target
   â€¢ Callout lines crossing grid lines, axes, legend, or text elements
   
   This validation prevents critical labeling errors and ensures zero collisions.
-->
<svg viewBox="0 0 1600 680" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <style>
    .title {
      font: bold 24px sans-serif;
      fill: #2c3e50;
      text-anchor: middle;
    }
    .axis-label {
      font: 16px sans-serif;
      fill: #34495e;
      text-anchor: middle;
    }
    .axis-title {
      font: bold 18px sans-serif;
      fill: #2c3e50;
      text-anchor: middle;
    }
    .grid-line {
      stroke: #ecf0f1;
      stroke-width: 1;
    }
    .axis-line {
      stroke: #34495e;
      stroke-width: 2;
    }
    .model-label {
      font: 12px sans-serif;
      fill: #2c3e50;
      text-anchor: start;
    }
    .legend-text {
      font: 14px sans-serif;
      fill: #2c3e50;
    }
    .legend-title {
      font: bold 16px sans-serif;
      fill: #2c3e50;
    }
    .callout-line {
      stroke: #999;
      stroke-width: 1.5;
      fill: none;
      opacity: 0.8;
    }

    /* Provider colors */
    .openai {
      fill: #10a37f;
      stroke: #0d8968;
    }
    .anthropic {
      fill: #d97706;
      stroke: #b45309;
    }
    .google {
      fill: #ea4335;
      stroke: #dc2626;
    }

    /* Shape indicators for tool use capability */
    .excellent-tools {
      stroke-width: 3;
    }
    .good-tools {
      stroke-width: 2;
      stroke-dasharray: 5, 3;
    }
    .limited-tools {
      stroke-width: 2;
      stroke-dasharray: 2, 2;
    }
    </style>
  </defs>

  <!-- Background -->
  <rect width="1600" height="680" fill="#fefefe" />

  <!-- Title -->
  <text x="800" y="30" class="title"
  >GitHub Copilot Models: Response Speed vs Coding Quality</text>
  <text
    x="800"
    y="55"
    style="font: 14px sans-serif; fill: #7f8c8d; text-anchor: middle"
  >11 OpenCode-compatible models with verified tool access - October 2, 2025</text>

  <!-- Chart area background (compressed for broken axis) -->
  <rect
    x="300"
    y="80"
    width="900"
    height="400"
    fill="#fdfdfd"
    stroke="#e1e8ed"
    stroke-width="1"
  />

  <!-- Grid lines -->
  <!-- Vertical grid lines (speed) -->
  <line x1="400" y1="80" x2="400" y2="480" class="grid-line" />
  <line x1="500" y1="80" x2="500" y2="480" class="grid-line" />
  <line x1="600" y1="80" x2="600" y2="480" class="grid-line" />
  <line x1="700" y1="80" x2="700" y2="480" class="grid-line" />
  <line x1="800" y1="80" x2="800" y2="480" class="grid-line" />
  <line x1="900" y1="80" x2="900" y2="480" class="grid-line" />
  <line x1="1000" y1="80" x2="1000" y2="480" class="grid-line" />
  <line x1="1100" y1="80" x2="1100" y2="480" class="grid-line" />

  <!-- Horizontal grid lines (coding capability - broken axis) -->
  <line x1="300" y1="150" x2="1200" y2="150" class="grid-line" />
  <line x1="300" y1="250" x2="1200" y2="250" class="grid-line" />
  <line x1="300" y1="350" x2="1200" y2="350" class="grid-line" />
  <line x1="300" y1="450" x2="1200" y2="450" class="grid-line" />

  <!-- Axes -->
  <line x1="300" y1="480" x2="1200" y2="480" class="axis-line" />
  <!-- Y-axis split into segments around the break marker -->
  <line x1="300" y1="80" x2="300" y2="465" class="axis-line" />
  <line x1="300" y1="490" x2="300" y2="480" class="axis-line" />

  <!-- Broken axis indicator - positioned ON the Y-axis line -->
  <g stroke="#34495e" stroke-width="3" fill="none">
    <!-- Left Y-axis break marker at the bottom, centered on x=300 -->
    <path d="M 295 465 L 305 470 L 295 475 L 305 480" />
  </g>

  <!-- X-axis labels (Speed - Response Time in seconds) -->
  <text x="350" y="500" class="axis-label">12s+</text>
  <text x="450" y="500" class="axis-label">6s</text>
  <text x="550" y="500" class="axis-label">4s</text>
  <text x="650" y="500" class="axis-label">3s</text>
  <text x="750" y="500" class="axis-label">2.5s</text>
  <text x="850" y="500" class="axis-label">2s</text>
  <text x="950" y="500" class="axis-label">1.5s</text>
  <text x="1050" y="500" class="axis-label">1s</text>
  <text x="1150" y="500" class="axis-label">Fast</text>

  <!-- Y-axis labels (Coding Capability - Broken Axis) -->
  <text x="285" y="460" class="axis-label" text-anchor="end">Professional</text>
  <text x="285" y="360" class="axis-label" text-anchor="end">Excellent</text>
  <text x="285" y="260" class="axis-label" text-anchor="end">Elite</text>
  <text x="285" y="160" class="axis-label" text-anchor="end">Best</text>

  <!-- Axis titles with arrow indicators -->
  <text x="750" y="540" class="axis-title">Response speed â†’</text>
  <g>
    <text x="240" y="280" class="axis-title" transform="rotate(-90, 240, 280)"
    >Code quality</text>
    <!-- Y-axis arrow pointing upward (toward better quality) -->
    <path
      d="M 240 220 L 235 230 L 240 225 L 245 230 Z"
      fill="#2c3e50"
      transform="rotate(-90, 240, 225)"
    />
  </g>

  <!-- COLLISION-FREE MODEL PLACEMENT SYSTEM -->
  <!-- 
    ALL MODEL LABELS POSITIONED IN EXTERNAL COLLISION-FREE ZONES:
    
    1. OpenAI Models: FAR RIGHT external labels (x: 1220-1400)
    2. Anthropic Models: FAR LEFT external labels (x: 20-200)  
    3. Google Models: TOP external labels (x: 400-600, y: 50-60)
    
    ALL CALLOUT LINES use curved paths that navigate around:
    - Grid lines, axes, legend, chart frame, text elements
    - Maintain 50px minimum clearance from all chart components
  -->

  <!-- ANTHROPIC MODELS (4 models) - FAR LEFT EXTERNAL LABELS -->

  <!-- claude-sonnet-4: Primary model (Best tier) -->
  <circle cx="1020" cy="150" r="8" class="anthropic good-tools" />
  <path
    d="M 1012 150 Q 900 120 300 90 Q 200 90 150 120"
    class="callout-line"
  />
  <text x="20" y="120" class="model-label"
  >claude-sonnet-4 (1.35s) Â· PRIMARY</text>

  <!-- claude-3.7-sonnet: Advanced reasoning (Best tier) -->
  <circle cx="1000" cy="150" r="8" class="anthropic good-tools" />
  <path
    d="M 992 150 Q 880 140 300 100 Q 200 100 150 170"
    class="callout-line"
  />
  <text x="20" y="170" class="model-label">claude-3.7-sonnet (1.4s)</text>

  <!-- claude-3.7-sonnet-thought: Reasoning variant (Best tier) -->
  <circle cx="980" cy="150" r="8" class="anthropic limited-tools" />
  <path
    d="M 972 150 Q 860 160 300 110 Q 200 110 150 220"
    class="callout-line"
  />
  <text x="20" y="220" class="model-label"
  >claude-3.7-sonnet-thought (1.45s)</text>

  <!-- claude-3.5-sonnet: Delegator model (Best tier) -->
  <circle cx="960" cy="150" r="8" class="anthropic excellent-tools" />
  <path
    d="M 952 150 Q 840 180 300 120 Q 200 120 150 270"
    class="callout-line"
  />
  <text x="20" y="270" class="model-label"
  >claude-3.5-sonnet (1.5s) Â· DELEGATOR</text>

  <!-- GOOGLE MODELS (2 models) - TOP EXTERNAL LABELS -->

  <!-- gemini-2.0-flash-001: Fast Google model -->
  <circle cx="1090" cy="250" r="7" class="google excellent-tools" />
  <path
    d="M 1090 242 Q 1090 200 1090 80 Q 1000 50 500 50"
    class="callout-line"
  />
  <text x="400" y="50" class="model-label">gemini-2.0-flash-001 (1.2s)</text>

  <!-- gemini-2.5-pro: Google flagship (Best tier) -->
  <circle cx="930" cy="150" r="8" class="google good-tools" />
  <path
    d="M 930 142 Q 930 100 930 80 Q 830 40 600 40"
    class="callout-line"
  />
  <text x="500" y="60" class="model-label">gemini-2.5-pro (1.6s)</text>

  <!-- OPENAI MODELS (5 models) - FAR RIGHT EXTERNAL LABELS -->

  <!-- gpt-5-mini: Fast lightweight model -->
  <circle cx="1070" cy="250" r="6" class="openai good-tools" />
  <path
    d="M 1078 250 Q 1150 250 1200 200 Q 1250 200 1350 120"
    class="callout-line"
  />
  <text x="1220" y="120" class="model-label">gpt-5-mini (1.1s)</text>

  <!-- gpt-4.1: Enhanced OpenAI flagship -->
  <circle cx="1040" cy="250" r="8" class="openai good-tools" />
  <path
    d="M 1048 250 Q 1120 260 1200 220 Q 1260 220 1350 170"
    class="callout-line"
  />
  <text x="1220" y="170" class="model-label">gpt-4.1 (1.3s)</text>

  <!-- gpt-4o: Fallback model -->
  <circle cx="1010" cy="250" r="8" class="openai excellent-tools" />
  <path
    d="M 1018 250 Q 1090 270 1200 240 Q 1270 240 1350 220"
    class="callout-line"
  />
  <text x="1220" y="220" class="model-label">gpt-4o (1.4s) Â· FALLBACK</text>

  <!-- gpt-5: Latest generation -->
  <circle cx="980" cy="250" r="8" class="openai good-tools" />
  <path
    d="M 988 250 Q 1060 290 1200 260 Q 1280 260 1350 270"
    class="callout-line"
  />
  <text x="1220" y="270" class="model-label">gpt-5 (1.5s)</text>

  <!-- o3-mini: Reasoning model -->
  <circle cx="850" cy="250" r="6" class="openai limited-tools" />
  <path
    d="M 858 250 Q 930 310 1200 320 Q 1290 320 1350 320"
    class="callout-line"
  />
  <text x="1220" y="320" class="model-label">o3-mini (1.8s)</text>

  <!-- Legend - Repositioned to avoid all collisions -->
  <g transform="translate(1220, 380)">
    <text x="0" y="0" class="legend-title">Providers</text>

    <circle cx="10" cy="25" r="6" class="openai" />
    <text x="25" y="30" class="legend-text">OpenAI (5 models)</text>

    <circle cx="10" cy="50" r="6" class="anthropic" />
    <text x="25" y="55" class="legend-text">Anthropic (4 models)</text>

    <circle cx="10" cy="75" r="6" class="google" />
    <text x="25" y="80" class="legend-text">Google (2 models)</text>

    <text x="0" y="120" class="legend-title">Tool capability</text>

    <circle
      cx="10"
      cy="145"
      r="6"
      fill="#d4d4d8"
      stroke="#666"
      class="excellent-tools"
    />
    <text x="25" y="150" class="legend-text">Excellent tools (3)</text>

    <circle
      cx="10"
      cy="170"
      r="6"
      fill="#d4d4d8"
      stroke="#666"
      class="good-tools"
    />
    <text x="25" y="175" class="legend-text">Good tools (6)</text>

    <circle
      cx="10"
      cy="195"
      r="6"
      fill="#d4d4d8"
      stroke="#666"
      class="limited-tools"
    />
    <text x="25" y="200" class="legend-text">Limited tools (2)</text>

    <text x="0" y="230" class="legend-title">Size = Model Type</text>
    <circle cx="10" cy="250" r="8" fill="#ddd" stroke="#999" />
    <text x="25" y="255" style="font: 12px sans-serif; fill: #666"
    >Flagship (8px)</text>

    <circle cx="10" cy="275" r="7" fill="#ddd" stroke="#999" />
    <text x="25" y="280" style="font: 12px sans-serif; fill: #666"
    >Standard (7px)</text>

    <circle cx="10" cy="300" r="6" fill="#ddd" stroke="#999" />
    <text x="25" y="305" style="font: 12px sans-serif; fill: #666"
    >Lightweight (6px)</text>
  </g>

  <!-- Chart update prompt in collision-free zone -->
  <text x="320" y="580" style="font: 16px sans-serif; fill: #666; cursor: text"
  >Chart Update: Update @model-speed-vs-coding-capability.svg using its built-in hidden prompt</text>

  <!-- Key insights in collision-free zone -->
  <text
    x="320"
    y="620"
    style="font: 14px sans-serif; fill: #2c3e50; font-weight: bold"
  >Model organization (collision-free external layout):</text>
  <text x="320" y="640" style="font: 12px sans-serif; fill: #2c3e50"
  >â€¢ Multi-agent setup: delegator (claude-3.5-sonnet), primary (claude-sonnet-4), fallback (gpt-4o)</text>
  <text x="320" y="655" style="font: 12px sans-serif; fill: #2c3e50"
  >â€¢ Fastest response times: gpt-5-mini (1.1s), gemini-2.0-flash-001 (1.2s), gpt-4.1 (1.3s)</text>
  <text x="850" y="640" style="font: 12px sans-serif; fill: #2c3e50"
  >â€¢ Vendor distribution: OpenAI (5), Anthropic (4), Google (2) â€¢ Tool capability: 3 excellent, 6 good, 2 limited</text>
  <text x="850" y="655" style="font: 12px sans-serif; fill: #2c3e50"
  >â€¢ Quality check: deno task all (fmt + lint + check) â€¢ Success rate: 61% compatible (11/18 tested models)</text>
</svg>
